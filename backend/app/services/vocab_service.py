import json
import os
from typing import List, Dict, Optional, Any

# Path to the JSON file generated by fetch_vocab.py
VOCAB_FILE = os.path.join(os.path.dirname(__file__), "..", "data", "vocab.json")


class VocabService:
    """Singleton service for managing in-memory vocabulary lookups."""

    _instance = None
    _vocab_map = {}
    _loaded = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(VocabService, cls).__new__(cls)
            cls._instance.load_vocab()
        return cls._instance

    def load_vocab(self):
        """Loads the vocabulary JSON into memory if not already loaded."""
        if self._loaded:
            return

        print("Loading vocabulary into memory...")
        if not os.path.exists(VOCAB_FILE):
            print("Warning: vocab.json not found. Run fetch_vocab.py first.")
            return

        try:
            with open(VOCAB_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
        except (IOError, json.JSONDecodeError) as e:
            print(f"Error loading vocab file: {e}")
            return

        # Optimize for lookup: Create a dict keyed by word AND reading
        # Handle multiple entries by picking the one with the best frequency rank
        for entry in data:
            self._add_entry(entry["word"], entry)
            # Also index by reading if it exists and is different from word
            if entry["reading"] and entry["reading"] != entry["word"]:
                self._add_entry(entry["reading"], entry)

        self._loaded = True
        print(f"Vocabulary loaded. Memory map size: {len(self._vocab_map)}")

    def _add_entry(self, key: str, entry: Dict[str, Any]):
        """Adds a vocabulary entry to the map, prioritizing lower frequency ranks.

        Args:
            key (str): The lookup key (word or reading).
            entry (Dict[str, Any]): The vocabulary entry data.
        """
        # If key exists, keep the one with the LOWER frequency rank (more common)
        # JMDict frequency logic: Lower rank # is better (1 is top, 10000 is rare)
        existing = self._vocab_map.get(key)

        # For kana lookups, prioritize kana_frequency_rank if available
        if key == entry.get("reading") and entry.get("kana_frequency_rank"):
            new_rank = entry.get("kana_frequency_rank")
        else:
            new_rank = entry.get("frequency_rank") or 999999

        if existing:
            if existing.get("reading") == key and existing.get("kana_frequency_rank"):
                old_rank = existing.get("kana_frequency_rank")
            else:
                old_rank = existing.get("frequency_rank") or 999999

            if new_rank < old_rank:
                self._vocab_map[key] = entry
        else:
            self._vocab_map[key] = entry

    def get_vocab(self, word: str) -> Optional[Dict[str, Any]]:
        """Retrieves a vocabulary entry by word or reading.

        Args:
            word (str): The word to look up.

        Returns:
            Optional[Dict[str, Any]]: The vocabulary entry or None.
        """
        return self._vocab_map.get(word)

    def enrich_tokens_from_memory(
        self, raw_tokens: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Enriches a list of raw tokens using the in-memory vocabulary map.

        Replaces 'crud.enrich_tokens' for offline/script usage.

        Args:
            raw_tokens (List[Dict[str, Any]]): List of raw tokens from the analyzer.

        Returns:
            List[Dict[str, Any]]: List of enriched tokens.
        """
        enriched = []
        for t in raw_tokens:
            base = t["base"]
            norm = t["normalized"]

            # Try Base
            match = self.get_vocab(base)

            # Try Normalized if Base failed
            if not match and norm != base:
                match = self.get_vocab(norm)
                if match:
                    base = norm  # Update base to the matched form

            # Default values
            level, reading, meanings, frequency, kana_freq = None, None, [], None, None

            if match:
                # Canonicalize the base to the dictionary word
                # Ensures stats_service counts unique words correctly
                base = match["word"]
                level = match["level"]
                reading = match["reading"]
                meanings = match["meanings"]
                frequency = match["frequency_rank"]
                kana_freq = match["kana_frequency_rank"]

            enriched.append(
                {
                    "surface": t["surface"],
                    "pos": t["pos"],
                    "base": base,
                    "level": level,
                    "reading": reading,
                    "meanings": meanings,
                    "frequency": frequency,
                    "kana_freq": kana_freq,
                    # Alternatives not supported in memory-mode
                    "alternatives": [],
                }
            )

        return enriched
